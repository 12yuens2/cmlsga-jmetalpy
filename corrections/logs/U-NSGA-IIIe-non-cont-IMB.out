Running SLURM prolog script on gold51.cluster.local
===============================================================================
Job started on Sun Sep 29 21:14:52 BST 2024
Job ID          : 6604712
Job name        : U-NSGA-IIIe-non-cont-IMB.slurm
WorkDir         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm
Command         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm/U-NSGA-IIIe-non-cont-IMB.slurm
Partition       : serial
Num hosts       : 1
Num cores       : 1
Num of tasks    : 1
Hosts allocated : gold51
Job Output Follows ...
===============================================================================
Running SLURM prolog script on gold51.cluster.local
===============================================================================
Job started on Sun Sep 29 21:14:52 BST 2024
Job ID          : 6604714
Job name        : U-NSGA-IIIe-non-cont-IMB.slurm
WorkDir         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm
Command         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm/U-NSGA-IIIe-non-cont-IMB.slurm
Partition       : serial
Num hosts       : 1
Num cores       : 1
Num of tasks    : 1
Hosts allocated : gold51
Job Output Follows ...
===============================================================================
Running SLURM prolog script on gold51.cluster.local
===============================================================================
Job started on Sun Sep 29 21:14:52 BST 2024
Job ID          : 6604713
Job name        : U-NSGA-IIIe-non-cont-IMB.slurm
WorkDir         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm
Command         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm/U-NSGA-IIIe-non-cont-IMB.slurm
Partition       : serial
Num hosts       : 1
Num cores       : 1
Num of tasks    : 1
Hosts allocated : gold51
Job Output Follows ...
===============================================================================
Running SLURM prolog script on gold51.cluster.local
===============================================================================
Job started on Sun Sep 29 21:14:52 BST 2024
Job ID          : 6604029
Job name        : U-NSGA-IIIe-non-cont-IMB.slurm
WorkDir         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm
Command         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm/U-NSGA-IIIe-non-cont-IMB.slurm
Partition       : serial
Num hosts       : 1
Num cores       : 1
Num of tasks    : 1
Hosts allocated : gold51
Job Output Follows ...
===============================================================================
Running SLURM prolog script on gold51.cluster.local
===============================================================================
Job started on Sun Sep 29 21:14:52 BST 2024
Job ID          : 6604715
Job name        : U-NSGA-IIIe-non-cont-IMB.slurm
WorkDir         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm
Command         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm/U-NSGA-IIIe-non-cont-IMB.slurm
Partition       : serial
Num hosts       : 1
Num cores       : 1
Num of tasks    : 1
Hosts allocated : gold51
Job Output Follows ...
===============================================================================
Running SLURM prolog script on gold51.cluster.local
===============================================================================
Job started on Sun Sep 29 21:14:52 BST 2024
Job ID          : 6604716
Job name        : U-NSGA-IIIe-non-cont-IMB.slurm
WorkDir         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm
Command         : /mainfs/home/sy6u19/cmlsga-jmetalpy/corrections/summary-slurm/U-NSGA-IIIe-non-cont-IMB.slurm
Partition       : serial
Num hosts       : 1
Num cores       : 1
Num of tasks    : 1
Hosts allocated : gold51
Job Output Follows ...
===============================================================================
/ssdfs/users/sy6u19/data-100000evals-30runs-corrections-normals/U-NSGA-IIIe-non-cont/IMB11
U-NSGA-IIIe-non-cont, IMB11
U-NSGA-IIIe-non-cont, IMB11
/ssdfs/users/sy6u19/data-100000evals-30runs-corrections-normals/U-NSGA-IIIe-non-cont/IMB14
U-NSGA-IIIe-non-cont, IMB14
U-NSGA-IIIe-non-cont, IMB14
/ssdfs/users/sy6u19/data-100000evals-30runs-corrections-normals/U-NSGA-IIIe-non-cont/IMB13
U-NSGA-IIIe-non-cont, IMB13
U-NSGA-IIIe-non-cont, IMB13
/ssdfs/users/sy6u19/data-100000evals-30runs-corrections-normals/U-NSGA-IIIe-non-cont/IMB10
U-NSGA-IIIe-non-cont, IMB10
U-NSGA-IIIe-non-cont, IMB10
/ssdfs/users/sy6u19/data-100000evals-30runs-corrections-normals/U-NSGA-IIIe-non-cont/IMB12
U-NSGA-IIIe-non-cont, IMB12
U-NSGA-IIIe-non-cont, IMB12
/ssdfs/users/sy6u19/data-100000evals-30runs-corrections-normals/U-NSGA-IIIe-non-cont/IMB9
U-NSGA-IIIe-non-cont, IMB9
U-NSGA-IIIe-non-cont, IMB9
==============================================================================
Running epilogue script on gold51.

==============================================================================
Running epilogue script on gold51.

==============================================================================
Running epilogue script on gold51.

Submit time  : 2024-09-29T19:10:40
Submit time  : 2024-09-29T19:10:40
==============================================================================
Running epilogue script on gold51.

==============================================================================
Running epilogue script on gold51.

Submit time  : 2024-09-29T19:10:40
Start time   : 2024-09-29T21:14:51
Start time   : 2024-09-29T21:14:51
Start time   : 2024-09-29T21:14:51
End time     : 2024-09-29T21:14:54
Submit time  : 2024-09-29T19:10:40
Submit time  : 2024-09-29T19:10:40
End time     : 2024-09-29T21:14:54
End time     : 2024-09-29T21:14:54
Start time   : 2024-09-29T21:14:51
Start time   : 2024-09-29T21:14:51
Elapsed time : 00:00:03 Elapsed time : 00:00:03 Elapsed time : 00:00:03 End time     : 2024-09-29T21:14:54
End time     : 2024-09-29T21:14:54
(Timelimit=1-23:55:00)

(Timelimit=1-23:55:00)

(Timelimit=1-23:55:00)

Elapsed time : 00:00:03 Elapsed time : 00:00:03 (Timelimit=1-23:55:00)

(Timelimit=1-23:55:00)

Job ID: 6604712
Array Job ID: 6604029_9
Cluster: i5
User/Group: sy6u19/mm
State: FAILED (exit code 1)
Cores: 1
CPU Utilized: 00:00:02
CPU Efficiency: 66.67% of 00:00:03 core-walltime
Job Wall-clock time: 00:00:03
Memory Utilized: 2.34 MB
Memory Efficiency: 0.03% of 7.81 GB

Job ID: 6604714
Array Job ID: 6604029_11
Cluster: i5
User/Group: sy6u19/mm
State: FAILED (exit code 1)
Cores: 1
CPU Utilized: 00:00:02
CPU Efficiency: 66.67% of 00:00:03 core-walltime
Job Wall-clock time: 00:00:03
Memory Utilized: 2.35 MB
Memory Efficiency: 0.03% of 7.81 GB

Job ID: 6604715
Array Job ID: 6604029_12
Cluster: i5
User/Group: sy6u19/mm
State: FAILED (exit code 1)
Cores: 1
CPU Utilized: 00:00:02
CPU Efficiency: 66.67% of 00:00:03 core-walltime
Job Wall-clock time: 00:00:03
Memory Utilized: 2.35 MB
Memory Efficiency: 0.03% of 7.81 GB

Job ID: 6604716
Array Job ID: 6604029_13
Cluster: i5
User/Group: sy6u19/mm
State: FAILED (exit code 1)
Cores: 1
CPU Utilized: 00:00:02
CPU Efficiency: 66.67% of 00:00:03 core-walltime
Job Wall-clock time: 00:00:03
Memory Utilized: 2.35 MB
Memory Efficiency: 0.03% of 7.81 GB
Job ID: 6604713
Array Job ID: 6604029_10
Cluster: i5
User/Group: sy6u19/mm
State: FAILED (exit code 1)
Cores: 1
CPU Utilized: 00:00:02
CPU Efficiency: 66.67% of 00:00:03 core-walltime
Job Wall-clock time: 00:00:03
Memory Utilized: 2.34 MB
Memory Efficiency: 0.03% of 7.81 GB


