Running SLURM prolog script on gold53.cluster.local
===============================================================================
Job started on Tue Oct 11 17:04:43 BST 2022
Job ID          : 1882195
Job name        : nsgaii-dascmop-5.slurm
WorkDir         : /mainfs/home/sy6u19/cmlsga-jmetalpy/smac
Command         : /mainfs/home/sy6u19/cmlsga-jmetalpy/smac/nsgaii-dascmop-5.slurm nsgaii-dascmop-6.slurm
Partition       : serial
Num hosts       : 1
Num cores       : 8
Num of tasks    : 8
Hosts allocated : gold53
Job Output Follows ...
===============================================================================
Running SLURM prolog script on gold57.cluster.local
===============================================================================
Job started on Tue Oct 11 17:04:44 BST 2022
Job ID          : 1882189
Job name        : nsgaii-dascmop-5.slurm
WorkDir         : /mainfs/home/sy6u19/cmlsga-jmetalpy/smac
Command         : /mainfs/home/sy6u19/cmlsga-jmetalpy/smac/nsgaii-dascmop-5.slurm nsgaii-dascmop-6.slurm
Partition       : serial
Num hosts       : 1
Num cores       : 8
Num of tasks    : 8
Hosts allocated : gold57
Job Output Follows ...
===============================================================================
==============================================================================
Running epilogue script on gold53.

Submit time  : 2022-10-11T17:02:45
Start time   : 2022-10-11T17:04:43
End time     : 2022-10-11T17:04:44
Elapsed time : 00:00:01 (Timelimit=1-00:05:00)

Job ID: 1882195
Array Job ID: 1882189_5
Cluster: i5
User/Group: sy6u19/mm
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 8
CPU Utilized: 00:00:02
CPU Efficiency: 25.00% of 00:00:08 core-walltime
Job Wall-clock time: 00:00:01
Memory Utilized: 2.55 MB
Memory Efficiency: 0.06% of 3.91 GB

