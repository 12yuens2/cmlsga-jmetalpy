{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "482c4feb-7be0-4c8e-8a55-2478d9ce4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from jmetal.core.algorithm import Algorithm\n",
    "from jmetal.core.quality_indicator import *\n",
    "from jmetal.util.solution import print_function_values_to_file, print_variables_to_file, read_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087395a-a35e-4027-98b4-89a71e28100f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e5dcc2a-34d8-45ff-ab99-c75a5efefdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_from_experiment(input_dir, quality_indicators, problems, evaluations,\n",
    "                                     reference_fronts = ''):\n",
    "    reference_change = 2500\n",
    "    ref_time = 1\n",
    "    if not quality_indicators:\n",
    "        quality_indicators = []\n",
    "        \n",
    "    with open('QualityIndicatorSummary.csv', 'w+') as of:\n",
    "        of.write('Algorithm,Problem,ExecutionId,Evaluations,IndicatorName,IndicatorValue\\n')\n",
    "\n",
    "    for dirname, _, filenames in os.walk(input_dir):\n",
    "        print(dirname)\n",
    "        for filename in sorted(filenames):\n",
    "            try:\n",
    "                # Linux filesystem\n",
    "                algorithm, problem = dirname.split('/')[-2:]\n",
    "            except ValueError:\n",
    "                # Windows filesystem\n",
    "                algorithm, problem = dirname.split('\\\\')[-2:]\n",
    "\n",
    "            for problem_name in problems:\n",
    "                if 'FUN' in filename and problem == problem_name:\n",
    "                    solutions = read_solutions(os.path.join(dirname, filename))\n",
    "                    digits = [s for s in filename.split('.') if s.isdigit()]\n",
    "                    run_tag = digits[0]\n",
    "                    evaluation_tag = evaluations\n",
    "                    if len(digits) > 1:\n",
    "                        evaluation_tag = digits[1]\n",
    "\n",
    "                    for indicator in quality_indicators:\n",
    "                        ref_time = min(int(int(evaluation_tag)/reference_change) + 1, 20)\n",
    "                        reference_front_file = \"resources/reference_front/{}_time{}.pf\".format(problem_name, ref_time) \n",
    "  \n",
    "                        # Add reference front if any\n",
    "                        if hasattr(indicator, 'reference_front'):\n",
    "                            if Path(reference_front_file).is_file():\n",
    "                                reference_front = []\n",
    "                                with open(reference_front_file) as file:\n",
    "                                    for line in file:\n",
    "                                        reference_front.append([float(x) for x in line.split()])\n",
    "\n",
    "                                indicator.reference_front = reference_front\n",
    "                            elif Path(\"resources/reference_front/{}.pf\".format(problem_name)).is_file():\n",
    "                                reference_front = []\n",
    "                                with open(\"resources/reference_front/{}.pf\".format(problem_name)) as file:\n",
    "                                    for line in file:\n",
    "                                        reference_front.append([float(x) for x in line.split()])\n",
    "\n",
    "                                indicator.reference_front = reference_front\n",
    "                            else:\n",
    "                                print(\"no reference front for {}\".format(problem))\n",
    "\n",
    "                        result = indicator.compute([solutions[i].objectives for i in range(len(solutions))])\n",
    "\n",
    "                        # Save quality indicator value to file\n",
    "                        with open('QualityIndicatorSummary.csv', 'a+') as of:\n",
    "                            of.write(','.join([algorithm, problem, str(run_tag), str(evaluation_tag), indicator.get_short_name(), str(result)]))\n",
    "                            of.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23522e3-599c-4482-b4ee-62aac333653e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9a050-2d7d-4a0c-a4e6-a1ed8bb2bd73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45821b-4142-45be-b5ed-c44f51e42c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170af4f-e60f-4931-ac89-a5ba8cfe6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1ba3f-7e0d-474a-8208-0979bea4f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pf(problem):\n",
    "    pf = pd.read_csv(\"resources/reference_front/{}_time1.pf\".format(problem), delimiter = \"\\t\")\n",
    "    pf2 = pd.read_csv(\"resources/reference_front/{}_time4.pf\".format(problem), delimiter = \"\\t\")\n",
    "    pf3 = pd.read_csv(\"resources/reference_front/{}_time8.pf\".format(problem), delimiter = \"\\t\")\n",
    "    \n",
    "    ax1 = pf.plot.scatter(x=0, y=1)\n",
    "    ax2 = pf2.plot.scatter(x=0, y=1, ax=ax1)\n",
    "    ax3 = pf3.plot.scatter(x=0, y=1, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad087f3b-0479-4bb6-b590-b45277c8648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.read_csv(\"resources/reference_front/CDF3_time2.pf\", delimiter = \"\\t\")\n",
    "ax = pf.plot.scatter(x=0, y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9af599-f615-454e-b32b-295a61605ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pf(\"CDF11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f8530-6ce0-44c7-ae82-bbcc2b97dae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4905a-556d-41ea-9592-5bf73bb80b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "023f9519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c7e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000cfda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416004f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "igd = df[(df[\"Problem\"] == \"UDF3\") & (df[\"Evaluations\"] == 1000) & (df[\"Algorithm\"] == \"MOEAD\")][\"IndicatorValue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af6647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f96d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(igd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f255b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(igd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "097645a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_cdf = [\"CDF1\", \"CDF2\", \"CDF3\", \"CDF4\", \"CDF5\", \"CDF6\", \"CDF7\", \"CDF8\",\n",
    "            \"CDF9\", \"CDF10\", \"CDF11\", \"CDF12\", \"CDF13\", \"CDF14\", \"CDF15\"]\n",
    "problems_udf = [\"UDF1\", \"UDF2\", \"UDF3\", \"UDF4\", \"UDF5\", \"UDF6\", \"UDF8\"]\n",
    "problems_jy = [\"JY1\", \"JY2\", \"JY3\", \"JY5\", \"JY6\", \"JY7\", \"JY8\"]\n",
    "problems_fda = [\"FDA1\", \"FDA2\", \"FDA3\"]\n",
    "problems_static = [\"ZDT1\", \"ZDT2\", \"ZDT3\", \"ZDT4\", \"ZDT6\",\n",
    "                  \"WFG1\", \"WFG2\", \"WFG3\", \"WFG4\", \"WFG5\", \"WFG6\", \"WFG7\", \"WFG8\", \"WFG9\",\n",
    "                  \"UF1\", \"UF2\", \"UF3\", \"UF4\", \"UF6\", \"UF7\", \"UF8\", \"UF9\", \"UF10\",\n",
    "                  \"IMB1\", \"IMB2\", \"IMB3\", \"IMB4\", \"IMB6\", \"IMB7\", \"IMB8\", \"IMB9\", \"IMB10\"\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7a7d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-500pop-100000evals-20runs-randomBlocksize1-var2\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/UDF3\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/UDF6\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/JY2\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/JY3\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/UDF1\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/UDF4\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/UDF2\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/JY5\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/JY6\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/JY7\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/UDF8\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/JY1\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/UDF5\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD-e/JY8\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD/UDF3\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD/UDF1\n",
      "data-500pop-100000evals-20runs-randomBlocksize1-var2/MOEAD/UDF2\n"
     ]
    }
   ],
   "source": [
    "output_directory = \"data-500pop-100000evals-20runs-randomBlocksize1-var2\"\n",
    "\n",
    "generate_summary_from_experiment(output_directory, [InvertedGenerationalDistance(None)], \n",
    "                                 problems_udf + problems_jy, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b759f50e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_igd_csv(filename, df, problems):\n",
    "    with open('igd.csv', 'w+') as of:\n",
    "            of.write('Algorithm,Problem,Evaluations,IGD-avg,IDG-std\\n')\n",
    "\n",
    "    for algorithm in [\"MOEAD\", \"MOEAD-e\"]:\n",
    "        for problem in problems:\n",
    "            for evals in range(1000, 100000, 1000):\n",
    "                igd_df = df[(df[\"Problem\"] == problem) \n",
    "                            & (df[\"Evaluations\"] == evals) \n",
    "                            & (df[\"Algorithm\"] == algorithm)][\"IndicatorValue\"]\n",
    "\n",
    "                with open(\"igd.csv\", \"a+\") as f:\n",
    "                    f.write(\",\".join([algorithm, problem, str(evals), str(np.average(igd_df)), str(np.std(igd_df))]))\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7212717d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_raw_csv(filename, df, problems):\n",
    "    with open(filename, \"w+\") as f:\n",
    "        for algorithm in [\"MOEAD\", \"MOEAD-e\"]:\n",
    "            for evals in range(1000, 101000, 1000):\n",
    "                f.write(\",\".join([algorithm, str(evals)]))\n",
    "                for problem in problems:\n",
    "                    igd_df = df[(df[\"Problem\"] == problem)\n",
    "                                & (df[\"Algorithm\"] == algorithm)\n",
    "                                & (df[\"Evaluations\"] == evals)]            \n",
    "\n",
    "                    f.write(\",{}\".format(problem))\n",
    "                    for i, row in igd_df.iterrows():\n",
    "                        f.write(\",{}\".format(row[\"IndicatorValue\"]))\n",
    "\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "619f5e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_block = pd.read_csv(\"randomBlock1-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56a7e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_proba = pd.read_csv(\"randomProba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0d042d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_block_var = pd.read_csv(\"randomBlock1-var2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3dc4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = problems_udf + problems_jy\n",
    "write_raw_csv(\"randomBlock1-10-raw.csv\", df_random_block, problems)\n",
    "write_raw_csv(\"randomBlock1-var2-raw.csv\", df_random_block_var, problems)\n",
    "write_raw_csv(\"randomProba-raw.csv\", df_random_proba, problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf84825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba80ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_average_igd(filename, df, problems):\n",
    "    with open(filename, \"w+\") as f:\n",
    "        f.write(\",\".join([\"Evaluations\"] + problems))\n",
    "        f.write(\"\\n\")\n",
    "        for evals in range(1000, 101000, 1000):\n",
    "            f.write(\"{}\".format(evals))\n",
    "            for problem in problems:\n",
    "                igd_df = df[(df[\"Problem\"] == problem)\n",
    "                           & (df[\"Algorithm\"] == \"MOEAD-e\")\n",
    "                           & (df[\"Evaluations\"] == evals)]\n",
    "                f.write(\",{}\".format(np.average(igd_df[\"IndicatorValue\"])))\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d4fbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_average_igd(\"average-igd.csv\", df_random_block, problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea3f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
